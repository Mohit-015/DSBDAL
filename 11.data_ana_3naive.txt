import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score

# Load the Iris dataset
df = pd.read_csv('iris.csv')  # Replace with the actual path of your CSV file

# Display the first few rows of the dataset
print("Dataset:\n", df.head())

# 1. Preprocess the data
# The last column is the target variable (Species), and the rest are features
X = df.drop('Species', axis=1)  # Features (sepal length, sepal width, petal length, petal width)
y = df['Species']  # Target variable (Species)

# 2. Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Create a Naive Bayes model
model = GaussianNB()

# 4. Train the model using the training data
model.fit(X_train, y_train)

# 5. Make predictions on the test set
y_pred = model.predict(X_test)

# 6. Compute the Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# 7. Compute Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("\nAccuracy:", accuracy)

# 8. Compute Error Rate
error_rate = 1 - accuracy
print("\nError Rate:", error_rate)

# 9. Compute Precision (for each class)
precision = precision_score(y_test, y_pred, average='macro')
print("\nPrecision:", precision)

# 10. Compute Recall (for each class)
recall = recall_score(y_test, y_pred, average='macro')
print("\nRecall:", recall)
